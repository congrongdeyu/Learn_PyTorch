{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.1 从 Python 列表到 PyTorch 张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "a = [1.0, 2.0, 1.0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.0, 2.0, 3.0]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 3.0\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 1.])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(3)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 2.])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.3 张量的本质"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4., 1., 5., 3., 2., 1.])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0\n",
    "points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4., 1., 5., 3., 2., 1.])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.0, 1.0)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[4., 1.],\n        [5., 3.],\n        [2., 1.]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 2])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0.],\n        [0., 0.],\n        [0., 0.]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3, 2)\n",
    "points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[4., 1.],\n        [5., 3.],\n        [2., 1.]])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4., 1.])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 索引张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5., 3.],\n        [2., 1.]])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5., 3.],\n        [2., 1.]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([5., 2.])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[4., 1.],\n         [5., 3.],\n         [2., 1.]]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 命名张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-1.5405, -0.8635, -0.8780,  1.1333,  1.2353],\n         [ 0.5900, -0.5115, -1.0327, -0.2437, -0.2828],\n         [-0.7858,  0.8200,  0.0332, -0.3024,  0.2668],\n         [ 1.0759,  1.3555, -0.3769,  0.4304, -1.1345],\n         [ 0.3911,  0.0601, -1.2359,  0.1458, -0.5775]],\n\n        [[-0.3361, -0.5447, -0.6013,  0.9648, -0.8102],\n         [ 0.0058,  0.0847, -0.8399, -0.6305,  1.4760],\n         [-0.0533, -0.6654,  0.5107,  1.6108, -0.0636],\n         [-0.0843,  0.2961,  0.4292, -0.0403,  0.5910],\n         [ 0.5189, -0.0557, -1.1104, -1.6029, -0.1218]],\n\n        [[-0.6936,  0.6164,  0.3463,  0.0081, -0.3586],\n         [-0.7756, -0.4723, -0.3524,  0.5900,  0.2108],\n         [ 0.1701, -1.0131, -0.9605, -0.1174,  1.4315],\n         [ 0.4463,  1.2121,  0.1126,  1.8416,  0.7648],\n         [ 0.4149, -0.1476, -0.6983, -0.0743,  1.3411]]])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5)\n",
    "img_t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2126, 0.7152, 0.0722])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-0.5542,  2.3576,  0.1943,  1.5308,  1.1323],\n          [ 0.9105,  0.5439, -0.4888, -0.4740, -0.2012],\n          [-1.0308, -1.8053,  1.2525, -0.2673, -0.8321],\n          [ 1.1008,  0.9821,  0.5802, -0.7527,  0.5258],\n          [ 1.2370, -0.9986,  0.2618, -0.5788,  0.8815]],\n\n         [[-0.7740,  0.5592, -0.6151,  1.4602,  0.2703],\n          [ 0.4741, -0.4367, -0.9186, -2.4352,  0.6936],\n          [-0.3328,  0.3677,  0.5530, -1.3658, -0.1727],\n          [-0.5503,  0.5740,  1.1759,  1.8552,  1.9016],\n          [ 2.1341,  1.7270, -0.5348,  1.0389,  1.1842]],\n\n         [[-1.0104, -0.7795,  0.5309, -0.4245,  0.7802],\n          [ 0.5191,  1.0021,  0.1250,  0.3412,  1.1504],\n          [-1.4196,  0.4387, -2.5478,  1.9443,  1.5243],\n          [ 1.5630, -0.5831,  1.6427, -0.7921, -1.3171],\n          [ 0.5173, -0.4396, -0.7433,  0.2009,  0.5115]]],\n\n\n        [[[ 2.9929,  1.6040,  1.5121, -0.0706,  0.7651],\n          [-0.0126,  0.5887, -0.1644,  0.1798, -0.8035],\n          [ 0.9009,  0.7176, -0.2010, -0.6626,  0.5092],\n          [-0.5234, -0.8243, -0.7938,  0.5281,  0.0297],\n          [-0.4502, -0.3624,  0.6230,  0.6103,  0.2072]],\n\n         [[-0.3006, -0.0859, -1.6070,  0.8302,  2.3642],\n          [-0.7320,  0.0334,  1.1720, -0.5275,  2.7023],\n          [ 0.9587,  0.5208,  1.4240,  0.4181, -0.1993],\n          [ 1.2854, -1.7111, -0.4135, -1.2434, -0.9358],\n          [ 1.3404,  1.5298,  0.0204, -0.9112, -0.7321]],\n\n         [[-0.6885, -0.8100,  0.2221,  1.0648, -1.8095],\n          [-2.1614, -0.2833, -2.4118,  1.4017, -1.3256],\n          [-0.4156,  1.1405,  0.7598,  1.3645,  0.2667],\n          [ 0.4873,  0.6934,  0.0812,  2.2613, -0.9670],\n          [ 0.0610,  1.8862, -0.5587, -0.9100, -0.6963]]]])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5)\n",
    "batch_t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.8567, -0.2639, -0.3777,  0.7021,  0.0222],\n        [-0.0599, -0.2997, -0.7417, -0.0948,  0.4680],\n        [-0.2230, -0.2862, -0.1388,  0.3970,  0.5449],\n        [ 0.4793,  0.9546,  0.0550,  0.7439,  0.0738],\n        [ 0.4417, -0.0477, -1.0148, -0.5104,  0.2140]])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿倒数第三个维度计算平均值\n",
    "img_gray_native = img_t.mean(-3)\n",
    "img_gray_native"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.7795,  0.7125,  0.0367,  0.8555,  0.7276],\n         [ 0.6346,  0.3697, -0.4275, -0.8560,  0.5476],\n         [-0.9277, -0.3330, -0.2474,  0.1038,  0.1731],\n         [ 0.7045,  0.3244,  1.1329,  0.1034,  0.3701],\n         [ 1.2962,  0.0963, -0.3387,  0.2203,  0.8591]],\n\n        [[ 0.6680,  0.2360,  0.0424,  0.6081,  0.4399],\n         [-0.9687,  0.1129, -0.4681,  0.3514,  0.1911],\n         [ 0.4813,  0.7930,  0.6609,  0.3733,  0.1922],\n         [ 0.4164, -0.6140, -0.3754,  0.5153, -0.6244],\n         [ 0.3170,  1.0178,  0.0282, -0.4036, -0.4070]]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gray_native = batch_t.mean(-3)\n",
    "batch_gray_native"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_native.shape, batch_gray_native.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2126, 0.7152, 0.0722])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.2126]],\n \n         [[0.7152]],\n \n         [[0.0722]]]),\n torch.Size([3, 1, 1]))"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1)\n",
    "unsqueezed_weights, unsqueezed_weights.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[-3.2751e-01, -1.8358e-01, -1.8667e-01,  2.4095e-01,  2.6263e-01],\n          [ 1.2543e-01, -1.0875e-01, -2.1956e-01, -5.1820e-02, -6.0124e-02],\n          [-1.6707e-01,  1.7433e-01,  7.0683e-03, -6.4280e-02,  5.6712e-02],\n          [ 2.2874e-01,  2.8817e-01, -8.0136e-02,  9.1503e-02, -2.4120e-01],\n          [ 8.3154e-02,  1.2776e-02, -2.6275e-01,  3.1006e-02, -1.2277e-01]],\n \n         [[-2.4035e-01, -3.8955e-01, -4.3002e-01,  6.9003e-01, -5.7948e-01],\n          [ 4.1146e-03,  6.0586e-02, -6.0071e-01, -4.5093e-01,  1.0556e+00],\n          [-3.8124e-02, -4.7591e-01,  3.6528e-01,  1.1521e+00, -4.5454e-02],\n          [-6.0294e-02,  2.1174e-01,  3.0697e-01, -2.8843e-02,  4.2268e-01],\n          [ 3.7115e-01, -3.9815e-02, -7.9413e-01, -1.1464e+00, -8.7097e-02]],\n \n         [[-5.0080e-02,  4.4507e-02,  2.5005e-02,  5.8342e-04, -2.5893e-02],\n          [-5.5995e-02, -3.4101e-02, -2.5445e-02,  4.2595e-02,  1.5217e-02],\n          [ 1.2283e-02, -7.3146e-02, -6.9350e-02, -8.4767e-03,  1.0336e-01],\n          [ 3.2222e-02,  8.7517e-02,  8.1318e-03,  1.3296e-01,  5.5218e-02],\n          [ 2.9957e-02, -1.0659e-02, -5.0416e-02, -5.3636e-03,  9.6830e-02]]]),\n torch.Size([3, 5, 5]))"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_weights = (img_t * unsqueezed_weights)\n",
    "img_weights, img_weights.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-0.1178,  0.5012,  0.0413,  0.3254,  0.2407],\n          [ 0.1936,  0.1156, -0.1039, -0.1008, -0.0428],\n          [-0.2191, -0.3838,  0.2663, -0.0568, -0.1769],\n          [ 0.2340,  0.2088,  0.1234, -0.1600,  0.1118],\n          [ 0.2630, -0.2123,  0.0557, -0.1231,  0.1874]],\n\n         [[-0.5536,  0.3999, -0.4399,  1.0443,  0.1933],\n          [ 0.3390, -0.3123, -0.6569, -1.7416,  0.4961],\n          [-0.2380,  0.2630,  0.3955, -0.9768, -0.1235],\n          [-0.3936,  0.4105,  0.8410,  1.3268,  1.3600],\n          [ 1.5263,  1.2351, -0.3825,  0.7430,  0.8470]],\n\n         [[-0.0729, -0.0563,  0.0383, -0.0306,  0.0563],\n          [ 0.0375,  0.0723,  0.0090,  0.0246,  0.0831],\n          [-0.1025,  0.0317, -0.1840,  0.1404,  0.1101],\n          [ 0.1128, -0.0421,  0.1186, -0.0572, -0.0951],\n          [ 0.0373, -0.0317, -0.0537,  0.0145,  0.0369]]],\n\n\n        [[[ 0.6363,  0.3410,  0.3215, -0.0150,  0.1627],\n          [-0.0027,  0.1252, -0.0349,  0.0382, -0.1708],\n          [ 0.1915,  0.1526, -0.0427, -0.1409,  0.1083],\n          [-0.1113, -0.1752, -0.1688,  0.1123,  0.0063],\n          [-0.0957, -0.0770,  0.1325,  0.1298,  0.0441]],\n\n         [[-0.2150, -0.0614, -1.1493,  0.5937,  1.6909],\n          [-0.5236,  0.0239,  0.8382, -0.3772,  1.9327],\n          [ 0.6857,  0.3725,  1.0184,  0.2990, -0.1426],\n          [ 0.9193, -1.2238, -0.2958, -0.8893, -0.6693],\n          [ 0.9586,  1.0941,  0.0146, -0.6517, -0.5236]],\n\n         [[-0.0497, -0.0585,  0.0160,  0.0769, -0.1306],\n          [-0.1560, -0.0205, -0.1741,  0.1012, -0.0957],\n          [-0.0300,  0.0823,  0.0549,  0.0985,  0.0193],\n          [ 0.0352,  0.0501,  0.0059,  0.1633, -0.0698],\n          [ 0.0044,  0.1362, -0.0403, -0.0657, -0.0503]]]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "batch_weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.6179, -0.5286, -0.5917,  0.9316, -0.3427],\n        [ 0.0736, -0.0823, -0.8457, -0.4602,  1.0107],\n        [-0.1929, -0.3747,  0.3030,  1.0793,  0.1146],\n        [ 0.2007,  0.5874,  0.2350,  0.1956,  0.2367],\n        [ 0.4843, -0.0377, -1.1073, -1.1207, -0.1130]])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted = img_weights.sum(-3)\n",
    "img_gray_weighted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.7443,  0.8449, -0.3603,  1.3391,  0.4904],\n         [ 0.5701, -0.1244, -0.7518, -1.8178,  0.5363],\n         [-0.5597, -0.0891,  0.4779, -0.8932, -0.1904],\n         [-0.0467,  0.5772,  1.0830,  1.1096,  1.3767],\n         [ 1.8267,  0.9911, -0.3805,  0.6345,  1.0713]],\n\n        [[ 0.3716,  0.2211, -0.8118,  0.6556,  1.7229],\n         [-0.6823,  0.1286,  0.6292, -0.2378,  1.6662],\n         [ 0.8472,  0.6074,  1.0305,  0.2567, -0.0151],\n         [ 0.8432, -1.3489, -0.4587, -0.6138, -0.7328],\n         [ 0.8673,  1.1532,  0.1067, -0.5876, -0.5298]]])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_gray_weighted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dingy\\AppData\\Local\\Temp\\ipykernel_10176\\2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10/core/TensorImpl.h:1761.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.5.2 适合任何场合的 dtype\n",
    "32 位浮点数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.float32"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.0).dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.6 张量的 API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1., 1.],\n         [1., 1.],\n         [1., 1.]]),\n tensor([[1., 1., 1.],\n         [1., 1., 1.]]),\n torch.Size([3, 2]),\n torch.Size([2, 3]))"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转置\n",
    "a = torch.ones(3, 2)\n",
    "a_t = torch.transpose(a, 0, 1)\n",
    "a, a_t, a.shape, a_t.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.7 张量的存储视图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.7.1 索引存储区"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": " 4.0\n 1.0\n 5.0\n 3.0\n 2.0\n 1.0\n[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.8.1 另一个张量的存储视图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([5., 3.])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.storage_offset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 1)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
